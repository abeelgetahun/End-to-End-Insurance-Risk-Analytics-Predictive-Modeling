{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0d5bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading insurance data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling.data_preprocessor:Claim severity dataset: 2788 records with claims\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1000098, 52)\n",
      "Columns: ['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth', 'IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode', 'VehicleType', 'RegistrationYear', 'make', 'Model', 'Cylinders', 'cubiccapacity', 'kilowatts', 'bodytype', 'NumberOfDoors', 'VehicleIntroDate', 'CustomValueEstimate', 'AlarmImmobiliser', 'TrackingDevice', 'CapitalOutstanding', 'NewVehicle', 'WrittenOff', 'Rebuilt', 'Converted', 'CrossBorder', 'NumberOfVehiclesInFleet', 'SumInsured', 'TermFrequency', 'CalculatedPremiumPerTerm', 'ExcessSelected', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType', 'TotalPremium', 'TotalClaims']\n",
      "Preparing claim severity dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:modeling.data_preprocessor:Column 'NumberOfVehiclesInFleet' has all NaNs. Filled with 0.\n",
      "INFO:modeling.data_preprocessor:Missing values handled. Remaining missing: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claim severity dataset shape: (2788, 54)\n",
      "Engineering features...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bin_edgess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Feature Engineering\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEngineering features...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m claim_data = \u001b[43mfeature_engineer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_risk_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclaim_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m claim_data = feature_engineer.create_interaction_features(claim_data)\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mData shape after feature engineering: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclaim_data.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\OneDrive\\Documents\\programs\\projects\\End-to-End-Insurance-Risk-Analytics-Predictive-Modeling\\notebooks\\../src\\modeling\\feature_engineer.py:36\u001b[39m, in \u001b[36mFeatureEngineer.create_risk_features\u001b[39m\u001b[34m(self, df)\u001b[39m\n\u001b[32m     33\u001b[39m df_features = df.copy()\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Vehicle-based risk features\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m df_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_vehicle_risk_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Geographic risk features\u001b[39;00m\n\u001b[32m     39\u001b[39m df_features = \u001b[38;5;28mself\u001b[39m._create_geographic_risk_features(df_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hp\\OneDrive\\Documents\\programs\\projects\\End-to-End-Insurance-Risk-Analytics-Predictive-Modeling\\notebooks\\../src\\modeling\\feature_engineer.py:83\u001b[39m, in \u001b[36mFeatureEngineer._create_vehicle_risk_features\u001b[39m\u001b[34m(self, df)\u001b[39m\n\u001b[32m     81\u001b[39m q25, q50, q75 = value_series.quantile([\u001b[32m0.25\u001b[39m, \u001b[32m0.5\u001b[39m, \u001b[32m0.75\u001b[39m])\n\u001b[32m     82\u001b[39m bin_edges = [value_series.min(), q25, q50, q75, value_series.max()]\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m bin_edges = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mbin_edgess\u001b[49m))  \u001b[38;5;66;03m# Remove duplicates\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ‘‰ Bin edges (deduplicated): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbin_edges\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bin_edges) == \u001b[32m5\u001b[39m:\n",
      "\u001b[31mNameError\u001b[39m: name 'bin_edgess' is not defined"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "Claim Severity Modeling Pipeline\n",
    "===============================\n",
    "\n",
    "This notebook implements the complete pipeline for predicting claim severity\n",
    "(TotalClaims for policies with claims > 0).\n",
    "\n",
    "Business Objective:\n",
    "- Predict the financial impact of claims to help with reserving and pricing\n",
    "- Identify key factors that drive claim severity\n",
    "- Support risk-based pricing decisions\n",
    "\"\"\"\n",
    "\n",
    "# %%\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to Python path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from modeling.data_preprocessor import DataPreprocessor\n",
    "from modeling.feature_engineer import FeatureEngineer\n",
    "from modeling.model_trainer import ModelTrainer\n",
    "from modeling.model_evaluator import ModelEvaluator\n",
    "from modeling.model_interpreter import ModelInterpreter\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# %%\n",
    "# Load the data\n",
    "print(\"Loading insurance data...\")\n",
    "data = pd.read_csv('../data/raw/insurance_data.csv')  # Adjust path as needed\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(f\"Columns: {list(data.columns)}\")\n",
    "\n",
    "# %%\n",
    "# Initialize preprocessing pipeline\n",
    "preprocessor = DataPreprocessor(random_state=42)\n",
    "feature_engineer = FeatureEngineer()\n",
    "\n",
    "print(\"Preparing claim severity dataset...\")\n",
    "# Prepare data for claim severity modeling (only policies with claims)\n",
    "claim_data = preprocessor.prepare_claim_severity_data(data)\n",
    "print(f\"Claim severity dataset shape: {claim_data.shape}\")\n",
    "\n",
    "# %%\n",
    "# Feature Engineering\n",
    "print(\"Engineering features...\")\n",
    "\n",
    "claim_data = feature_engineer.create_risk_features(claim_data)\n",
    "claim_data = feature_engineer.create_interaction_features(claim_data)\n",
    "\n",
    "print(f\"Data shape after feature engineering: {claim_data.shape}\")\n",
    "\n",
    "# %%\n",
    "# Data preprocessing\n",
    "print(\"Encoding categorical features...\")\n",
    "claim_data_encoded = preprocessor.encode_categorical_features(claim_data, encoding_strategy='mixed')\n",
    "\n",
    "# Prepare features and target\n",
    "# Remove target and other non-feature columns\n",
    "exclude_columns = ['TotalClaims', 'PolicyID', 'UnderwrittenCoverID', 'TransactionMonth']\n",
    "feature_columns = [col for col in claim_data_encoded.columns if col not in exclude_columns]\n",
    "\n",
    "X = claim_data_encoded[feature_columns]\n",
    "y = claim_data_encoded['TotalClaims']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "\n",
    "# %%\n",
    "# Train-test split\n",
    "print(\"Splitting data into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = preprocessor.split_data(X, y, test_size=0.2)\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled, X_test_scaled = preprocessor.scale_features(X_train, X_test)\n",
    "\n",
    "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
    "\n",
    "# %%\n",
    "# Feature Selection\n",
    "print(\"Performing feature selection...\")\n",
    "X_train_selected, selected_features = feature_engineer.select_features(\n",
    "    X_train_scaled, y_train, method='mutual_info', k=20, problem_type='regression'\n",
    ")\n",
    "\n",
    "# Apply same feature selection to test set\n",
    "X_test_selected = X_test_scaled[selected_features]\n",
    "\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "print(f\"Reduced feature matrix shape: {X_train_selected.shape}\")\n",
    "\n",
    "# %%\n",
    "# Model Training\n",
    "print(\"Training multiple models for claim severity prediction...\")\n",
    "\n",
    "model_trainer = ModelTrainer(random_state=42)\n",
    "\n",
    "# Train all models (without hyperparameter tuning for speed, but you can enable it)\n",
    "models = model_trainer.train_all_models(\n",
    "    X_train_selected, y_train, \n",
    "    problem_type='regression', \n",
    "    tune_hyperparameters=False,  # Set to True for better performance\n",
    "    cv_folds=5\n",
    ")\n",
    "\n",
    "print(\"Model training completed!\")\n",
    "\n",
    "# %%\n",
    "# Model Evaluation\n",
    "print(\"Evaluating models...\")\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    eval_result = evaluator.evaluate_regression_model(\n",
    "        model, model_name, X_test_selected, y_test, y_train, X_train_selected\n",
    "    )\n",
    "    evaluation_results[model_name] = eval_result\n",
    "\n",
    "# %%\n",
    "# Model Comparison\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "comparison_df = evaluator.compare_models(metric='rmse', problem_type='regression')\n",
    "print(comparison_df)\n",
    "\n",
    "# Also compare RÂ² scores\n",
    "r2_comparison = evaluator.compare_models(metric='r2_score', problem_type='regression')\n",
    "print(\"\\nRÂ² Score Comparison:\")\n",
    "print(r2_comparison)\n",
    "\n",
    "# %%\n",
    "# Visualize model performance\n",
    "best_model_name = comparison_df.iloc[0]['model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"\\nCreating evaluation plots for best model: {best_model_name}\")\n",
    "evaluator.plot_regression_results(\n",
    "    best_model, best_model_name, X_test_selected, y_test, \n",
    "    save_path='../reports/figures/modeling'\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Model Interpretation\n",
    "print(\"Performing model interpretation...\")\n",
    "\n",
    "interpreter = ModelInterpreter()\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importance = interpreter.analyze_feature_importance(\n",
    "    best_model, best_model_name, X_test_selected, y_test, \n",
    "    feature_names=selected_features, top_n=15\n",
    ")\n",
    "\n",
    "# %%\n",
    "# SHAP Analysis\n",
    "print(\"Computing SHAP values...\")\n",
    "shap_values, shap_importance = interpreter.analyze_shap_values(\n",
    "    best_model, best_model_name, X_train_selected, X_test_selected, \n",
    "    feature_names=selected_features, sample_size=100\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Business Insights\n",
    "print(\"Generating business insights...\")\n",
    "business_insights = interpreter.generate_business_insights(\n",
    "    best_model_name, feature_names=selected_features\n",
    ")\n",
    "\n",
    "print(\"\\nKey Risk Drivers:\")\n",
    "for driver in business_insights['key_risk_drivers'][:5]:\n",
    "    print(f\"- {driver['feature']}: {driver['business_meaning']}\")\n",
    "\n",
    "print(\"\\nBusiness Recommendations:\")\n",
    "for rec in business_insights['business_recommendations']:\n",
    "    print(f\"- {rec}\")\n",
    "\n",
    "# %%\n",
    "# Save Models and Results\n",
    "print(\"Saving models and results...\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('../models/claim_severity', exist_ok=True)\n",
    "os.makedirs('../reports/figures/modeling', exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "model_trainer.save_models('../models/claim_severity/claim_severity_model')\n",
    "\n",
    "# Save preprocessing objects\n",
    "preprocessor.save_preprocessors('../models/claim_severity/preprocessor.joblib')\n",
    "\n",
    "# Generate evaluation report\n",
    "evaluation_report = evaluator.generate_evaluation_report(\n",
    "    save_path='../reports/figures/modeling'\n",
    ")\n",
    "\n",
    "# Generate interpretation report\n",
    "interpretation_report = interpreter.create_interpretation_report(\n",
    "    best_model_name, save_path='../reports/figures/modeling'\n",
    ")\n",
    "\n",
    "print(\"Claim severity modeling pipeline completed successfully!\")\n",
    "\n",
    "# %%\n",
    "# Final Results Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLAIM SEVERITY MODELING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"RMSE: {evaluation_results[best_model_name]['rmse']:.2f}\")\n",
    "print(f\"RÂ² Score: {evaluation_results[best_model_name]['r2_score']:.4f}\")\n",
    "print(f\"MAPE: {evaluation_results[best_model_name]['mape']:.2f}%\")\n",
    "\n",
    "print(f\"\\nTop 5 Most Important Features:\")\n",
    "if best_model_name in interpreter.feature_importance:\n",
    "    importance_data = interpreter.feature_importance[best_model_name]['built_in']\n",
    "    top_features = sorted(importance_data.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for i, (feature, importance) in enumerate(top_features, 1):\n",
    "        print(f\"{i}. {feature}: {importance:.4f}\")\n",
    "\n",
    "print(\"\\nModel files saved to: ../models/claim_severity/\")\n",
    "print(\"Evaluation reports saved to: ../reports/figures/modeling/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
