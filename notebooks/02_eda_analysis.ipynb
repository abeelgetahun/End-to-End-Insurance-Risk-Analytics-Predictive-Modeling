{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Insurance Data - Comprehensive Exploratory Data Analysis (EDA)\n",
        "\n",
        "This notebook provides a comprehensive analysis of insurance data including data quality assessment, descriptive statistics, univariate and bivariate analysis, and advanced visualizations.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Setup and Data Loading](#setup)\n",
        "2. [Data Quality Assessment](#quality)\n",
        "3. [Descriptive Statistics](#descriptive)\n",
        "4. [Univariate Analysis](#univariate)\n",
        "5. [Bivariate Analysis](#bivariate)\n",
        "6. [Advanced Visualizations](#advanced)\n",
        "7. [Outlier Detection](#outliers)\n",
        "8. [Key Findings and Insights](#findings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Data Loading {#setup}\n",
        "\n",
        "First, let's import all necessary libraries and load our processed insurance data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "\n",
        "# Configure display settings\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 20)\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the processed insurance data\n",
        "df = pd.read_csv('../data/processed/insurance_data.csv')\n",
        "\n",
        "print(f\"Data loaded successfully!\")\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first few rows and basic info\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Quality Assessment {#quality}\n",
        "\n",
        "Let's assess the quality of our data by examining missing values, data types, and basic statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def assess_data_quality(df):\n",
        "    \"\"\"Comprehensive data quality assessment\"\"\"\n",
        "    \n",
        "    # Missing values analysis\n",
        "    missing_data = df.isnull().sum()\n",
        "    missing_percent = (missing_data / len(df)) * 100\n",
        "    \n",
        "    missing_df = pd.DataFrame({\n",
        "        'Column': missing_data.index,\n",
        "        'Missing Count': missing_data.values,\n",
        "        'Missing Percentage': missing_percent.values\n",
        "    }).sort_values('Missing Percentage', ascending=False)\n",
        "    \n",
        "    return missing_df\n",
        "\n",
        "# Assess data quality\n",
        "missing_summary = assess_data_quality(df)\n",
        "\n",
        "print(\"Missing Values Summary:\")\n",
        "display(missing_summary[missing_summary['Missing Percentage'] > 0].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data types summary\n",
        "print(\"Data Types Summary:\")\n",
        "dtype_summary = df.dtypes.value_counts().to_frame('Count')\n",
        "dtype_summary.index.name = 'Data Type'\n",
        "display(dtype_summary)\n",
        "\n",
        "print(f\"\\nNumeric columns: {df.select_dtypes(include=[np.number]).columns.tolist()}\")\n",
        "print(f\"Categorical columns: {df.select_dtypes(include=['object']).columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Descriptive Statistics {#descriptive}\n",
        "\n",
        "Now let's examine the descriptive statistics for our numerical variables and key business metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Numeric columns summary\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "print(f\"Descriptive Statistics for Numeric Columns ({len(numeric_cols)} columns):\")\n",
        "display(df[numeric_cols].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate key financial metrics\n",
        "if 'TotalPremium' in df.columns and 'TotalClaims' in df.columns:\n",
        "    # Calculate Loss Ratio\n",
        "    df['LossRatio'] = df['TotalClaims'] / df['TotalPremium']\n",
        "    df['LossRatio'] = df['LossRatio'].replace([np.inf, -np.inf], np.nan)\n",
        "    \n",
        "    print(\"Key Financial Metrics:\")\n",
        "    print(f\"Total Premium Sum: ${df['TotalPremium'].sum():,.2f}\")\n",
        "    print(f\"Total Claims Sum: ${df['TotalClaims'].sum():,.2f}\")\n",
        "    print(f\"Overall Loss Ratio: {df['TotalClaims'].sum() / df['TotalPremium'].sum():.3f}\")\n",
        "    print(f\"Average Loss Ratio: {df['LossRatio'].mean():.3f}\")\n",
        "    print(f\"Median Loss Ratio: {df['LossRatio'].median():.3f}\")\n",
        "    \n",
        "    # Loss ratio statistics\n",
        "    print(\"\\nLoss Ratio Distribution:\")\n",
        "    display(df['LossRatio'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Univariate Analysis {#univariate}\n",
        "\n",
        "Let's explore the distribution of individual variables, starting with numerical variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Numerical Variables Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_numerical_distributions(df, columns, ncols=3):\n",
        "    \"\"\"Plot distributions for numerical columns\"\"\"\n",
        "    n_rows = (len(columns) + ncols - 1) // ncols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, ncols, figsize=(15, 5*n_rows))\n",
        "    if n_rows == 1:\n",
        "        axes = [axes] if ncols == 1 else axes\n",
        "    else:\n",
        "        axes = axes.ravel()\n",
        "    \n",
        "    for i, col in enumerate(columns):\n",
        "        if i < len(axes) and col in df.columns:\n",
        "            # Remove outliers for better visualization\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            filtered_data = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)][col]\n",
        "            \n",
        "            axes[i].hist(filtered_data.dropna(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "            axes[i].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
        "            axes[i].set_xlabel(col)\n",
        "            axes[i].set_ylabel('Frequency')\n",
        "            axes[i].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add statistics text\n",
        "            mean_val = df[col].mean()\n",
        "            median_val = df[col].median()\n",
        "            axes[i].axvline(mean_val, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_val:.2f}')\n",
        "            axes[i].axvline(median_val, color='green', linestyle='--', alpha=0.7, label=f'Median: {median_val:.2f}')\n",
        "            axes[i].legend()\n",
        "    \n",
        "    # Remove empty subplots\n",
        "    for i in range(len(columns), len(axes)):\n",
        "        fig.delaxes(axes[i])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot key numerical distributions\n",
        "key_numeric_cols = ['TotalPremium', 'TotalClaims', 'SumInsured', 'CalculatedPremiumPerTerm']\n",
        "available_cols = [col for col in key_numeric_cols if col in df.columns]\n",
        "\n",
        "if available_cols:\n",
        "    print(\"Distribution of Key Numerical Variables:\")\n",
        "    plot_numerical_distributions(df, available_cols)\nelse:\n",
        "    print(\"Key numerical columns not found in dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Categorical Variables Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_categorical_distributions(df, columns, ncols=2):\n",
        "    \"\"\"Plot distributions for categorical columns\"\"\"\n",
        "    n_rows = (len(columns) + ncols - 1) // ncols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, ncols, figsize=(15, 6*n_rows))\n",
        "    if n_rows == 1:\n",
        "        axes = [axes] if ncols == 1 else axes\n",
        "    else:\n",
        "        axes = axes.ravel()\n",
        "    \n",
        "    for i, col in enumerate(columns):\n",
        "        if i < len(axes) and col in df.columns:\n",
        "            # Get top 10 categories to avoid overcrowding\n",
        "            top_categories = df[col].value_counts().head(10)\n",
        "            \n",
        "            axes[i].bar(range(len(top_categories)), top_categories.values, color='lightcoral', alpha=0.7)\n",
        "            axes[i].set_title(f'Distribution of {col} (Top 10)', fontsize=12, fontweight='bold')\n",
        "            axes[i].set_xlabel(col)\n",
        "            axes[i].set_ylabel('Count')\n",
        "            axes[i].set_xticks(range(len(top_categories)))\n",
        "            axes[i].set_xticklabels(top_categories.index, rotation=45, ha='right')\n",
        "            axes[i].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add value labels on bars\n",
        "            for j, v in enumerate(top_categories.values):\n",
        "                axes[i].text(j, v + max(top_categories.values) * 0.01, str(v), ha='center')\n",
        "    \n",
        "    # Remove empty subplots\n",
        "    for i in range(len(columns), len(axes)):\n",
        "        fig.delaxes(axes[i])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot key categorical distributions\n",
        "key_categorical_cols = ['Province', 'Gender', 'VehicleType', 'make']\n",
        "available_cat_cols = [col for col in key_categorical_cols if col in df.columns]\n",
        "\n",
        "if available_cat_cols:\n",
        "    print(\"Distribution of Key Categorical Variables:\")\n",
        "    plot_categorical_distributions(df, available_cat_cols)\nelse:\n",
        "    print(\"Key categorical columns not found in dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Bivariate Analysis {#bivariate}\n",
        "\n",
        "Now let's explore relationships between variables, particularly focusing on loss ratios across different segments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Loss Ratio Analysis by Business Segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_loss_ratio_by_segments(df):\n",
        "    \"\"\"Analyze loss ratio across different segments\"\"\"\n",
        "    if 'LossRatio' not in df.columns:\n",
        "        if 'TotalClaims' in df.columns and 'TotalPremium' in df.columns:\n",
        "            df['LossRatio'] = df['TotalClaims'] / df['TotalPremium']\n",
        "            df['LossRatio'] = df['LossRatio'].replace([np.inf, -np.inf], np.nan)\n",
        "        else:\n",
        "            print(\"Cannot calculate loss ratio: TotalClaims or TotalPremium columns missing\")\n",
        "            return\n",
        "    \n",
        "    segments = ['Province', 'Gender', 'VehicleType']\n",
        "    available_segments = [seg for seg in segments if seg in df.columns]\n",
        "    \n",
        "    if not available_segments:\n",
        "        print(\"No segment columns available for analysis\")\n",
        "        return\n",
        "    \n",
        "    fig, axes = plt.subplots(1, len(available_segments), figsize=(6*len(available_segments), 6))\n",
        "    if len(available_segments) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for i, segment in enumerate(available_segments):\n",
        "        # Calculate loss ratio by segment\n",
        "        segment_analysis = df.groupby(segment).agg({\n",
        "            'LossRatio': 'mean',\n",
        "            'PolicyID': 'count',\n",
        "            'TotalPremium': 'sum',\n",
        "            'TotalClaims': 'sum'\n",
        "        }).reset_index()\n",
        "        \n",
        "        # Filter segments with sufficient data\n",
        "        segment_analysis = segment_analysis[segment_analysis['PolicyID'] >= 100]\n",
        "        segment_analysis = segment_analysis.sort_values('LossRatio', ascending=False).head(10)\n",
        "        \n",
        "        if len(segment_analysis) > 0:\n",
        "            bars = axes[i].bar(range(len(segment_analysis)), segment_analysis['LossRatio'], \n",
        "                             color='orange', alpha=0.7)\n",
        "            axes[i].set_title(f'Average Loss Ratio by {segment}', fontsize=12, fontweight='bold')\n",
        "            axes[i].set_xlabel(segment)\n",
        "            axes[i].set_ylabel('Average Loss Ratio')\n",
        "            axes[i].set_xticks(range(len(segment_analysis)))\n",
        "            axes[i].set_xticklabels(segment_analysis[segment], rotation=45, ha='right')\n",
        "            axes[i].grid(True, alpha=0.3)\n",
        "            axes[i].axhline(y=1.0, color='red', linestyle='--', alpha=0.7, label='Break-even')\n",
        "            axes[i].legend()\n",
        "            \n",
        "            # Add value labels on bars\n",
        "            for bar, value in zip(bars, segment_analysis['LossRatio']):\n",
        "                height = bar.get_height()\n",
        "                axes[i].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                           f'{value:.3f}', ha='center', va='bottom')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Analyze loss ratios\n",
        "print(\"Loss Ratio Analysis by Business Segments:\")\n",
        "analyze_loss_ratio_by_segments(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation matrix for numerical variables\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "correlation_matrix = df[numeric_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
        "plt.title('Correlation Matrix of Numerical Variables', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display strongest correlations\n",
        "print(\"Strongest Positive Correlations (> 0.5):\")\n",
        "strong_corr = correlation_matrix.unstack().sort_values(ascending=False)\n",
        "strong_corr = strong_corr[strong_corr < 1.0]  # Remove self-correlations\n",
        "strong_positive = strong_corr[strong_corr > 0.5].head(10)\n",
        "for pair, corr in strong_positive.items():\n",
        "    print(f\"{pair[0]} vs {pair[1]}: {corr:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Advanced Visualizations {#advanced}\n",
        "\n",
        "Let's create some advanced, interactive visualizations to gain deeper insights into our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Premium vs Claims Scatter Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Premium vs Claims Scatter with Loss Ratio Color\n",
        "if all(col in df.columns for col in ['TotalPremium', 'TotalClaims', 'LossRatio']):\n",
        "    # Sample data for better performance\n",
        "    sample_size = min(10000, len(df))\n",
        "    sample_df = df.sample(n=sample_size, random_state=42)\n",
        "    \n",
        "    # Remove extreme outliers for better visualization\n",
        "    sample_df = sample_df[\n",
        "        (sample_df['TotalPremium'] <= sample_df['TotalPremium'].quantile(0.95)) &\n",
        "        (sample_df['TotalClaims'] <= sample_df['TotalClaims'].quantile(0.95)) &\n",
        "        (sample_df['LossRatio'] <= 5)  # Cap loss ratio at 5 for visualization\n",
        "    ]\n",
        "    \n",
        "    hover_cols = [col for col in ['Province', 'VehicleType', 'Gender'] if col in df.columns]\n",
        "    \n",
        "    fig = px.scatter(\n",
        "        sample_df, \n",
        "        x='TotalPremium', \n",
        "        y='TotalClaims',\n",
        "        color='LossRatio',\n",
        "        size='SumInsured' if 'SumInsured' in df.columns else None,\n",
        "        hover_data=hover_cols,\n",
        "        title=f'Premium vs Claims Analysis (Sample of {len(sample_df):,} policies)',\n",
        "        color_continuous_scale='RdYlBu_r',\n",
        "        labels={\n",
        "            'TotalPremium': 'Total Premium ($)',\n",
        "            'TotalClaims': 'Total Claims ($)',\n",
        "            'LossRatio': 'Loss Ratio'\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # Add break-even line\n",
        "    max_val = max(sample_df['TotalPremium'].max(), sample_df['TotalClaims'].max())\n",
        "    fig.add_shape(\n",
        "        type=\"line\",\n",
        "        x0=0, y0=0, x1=max_val, y1=max_val,\n",
        "        line=dict(color=\"red\", width=2, dash=\"dash\"),\n",
        "    )\n",
        "    \n",
        "    fig.update_layout(height=600, showlegend=True)\n",
        "    fig.show()\nelse:\n",
        "    print(\"Required columns for scatter plot not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Time Series Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time Series Analysis\n",
        "if 'TransactionMonth' in df.columns:\n",
        "    # Convert to datetime if not already\n",
        "    df['TransactionMonth'] = pd.to_datetime(df['TransactionMonth'], errors='coerce')\n",
        "    \n",
        "    # Filter out invalid dates\n",
        "    df_time = df.dropna(subset=['TransactionMonth'])\n",
        "    \n",
        "    if len(df_time) > 0:\n",
        "        monthly_trends = df_time.groupby(df_time['TransactionMonth'].dt.to_period('M')).agg({\n",
        "            'TotalPremium': 'sum',\n",
        "            'TotalClaims': 'sum',\n",
        "            'PolicyID': 'count'\n",
        "        }).reset_index()\n",
        "        \n",
        "        monthly_trends['LossRatio'] = monthly_trends['TotalClaims'] / monthly_trends['TotalPremium']\n",
        "        monthly_trends['TransactionMonth'] = monthly_trends['TransactionMonth'].astype(str)\n",
        "        \n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            subplot_titles=('Monthly Premium Revenue', 'Monthly Claims Payout', \n",
        "                          'Monthly Policy Count', 'Monthly Loss Ratio'),\n",
        "            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
        "                   [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
        "        )\n",
        "        \n",
        "        # Premium trend\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=monthly_trends['TransactionMonth'], y=monthly_trends['TotalPremium'],\n",
        "                      name='Premium', line=dict(color='blue', width=3)),\n",
        "            row=1, col=1\n",
        "        )\n",
        "        \n",
        "        # Claims trend\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=monthly_trends['TransactionMonth'], y=monthly_trends['TotalClaims'],\n",
        "                      name='Claims', line=dict(color='red', width=3)),\n",
        "            row=1, col=2\n",
        "        )\n",
        "        \n",
        "        # Policy count trend\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=monthly_trends['TransactionMonth'], y=monthly_trends['PolicyID'],\n",
        "                      name='Policy Count', line=dict(color='green', width=3)),\n",
        "            row=2, col=1\n",
        "        )\n",
        "        \n",
        "        # Loss ratio trend\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=monthly_trends['TransactionMonth'], y=monthly_trends['LossRatio'],\n",
        "                      name='Loss Ratio', line=dict(color='orange', width=3)),\n",
        "            row=2, col=2\n",
        "        )\n",
        "        \n",
        "        # Add break-even line to loss ratio\n",
        "        fig.add_hline(y=1.0, line_dash=\"dash\", line_color=\"red\", \n",
        "                     annotation_text=\"Break-even\", row=2, col=2)\n",
        "        \n",
        "        fig.update_layout(height=600, title_text=\"Insurance Business Trends Over Time\", \n",
        "                         showlegend=False)\n",
        "        fig.update_xaxes(tickangle=45)\n",
        "        fig.show()\n",
        "    else:\n",
        "        print(\"No valid transaction dates found\")\nelse:\n",
        "    print(\"TransactionMonth column not available for time series analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Risk Heatmap by Province and Vehicle Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Risk Heatmap by Province and Vehicle Type\n",
        "if all(col in df.columns for col in ['Province', 'VehicleType', 'TotalClaims', 'TotalPremium']):\n",
        "    # Create risk matrix\n",
        "    risk_matrix = df.groupby(['Province', 'VehicleType']).agg({\n",
        "        'TotalClaims': 'sum',\n",
        "        'TotalPremium': 'sum',\n",
        "        'PolicyID': 'count'\n",
        "    }).reset_index()\n",
        "    \n",
        "    risk_matrix['LossRatio'] = risk_matrix['TotalClaims'] / risk_matrix['TotalPremium']\n",
        "    \n",
        "    # Filter for statistical significance (at least 50 policies)\n",
        "    risk_matrix = risk_matrix[risk_matrix['PolicyID'] >= 50]\n",
        "    \n",
        "    if len(risk_matrix) > 0:\n",
        "        # Pivot for heatmap\n",
        "        heatmap_data = risk_matrix.pivot(index='Province', columns='VehicleType', values='LossRatio')\n",
        "        \n",
        "        plt.figure(figsize=(12, 8))\n",
        "        sns.heatmap(heatmap_data, annot=True, cmap='RdYlBu_r', center=1.0, fmt='.3f',\n",
        "                   linewidths=0.5, cbar_kws={'label': 'Loss Ratio'})\n",
        "        plt.title('Risk Heatmap: Loss Ratio by Province and Vehicle Type\\n(Minimum 50 policies per cell)', \n",
        "                 fontsize=14, fontweight='bold')\n",
        "        plt.xlabel('Vehicle Type', fontweight='bold')\n",
        "        plt.ylabel('Province', fontweight='bold')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Display summary statistics\n",
        "        print(\"Risk Heatmap Summary:\")\n",
        "        print(f\"Total combinations analyzed: {len(risk_matrix)}\")\n",
        "        print(f\"Highest risk (Loss Ratio): {risk_matrix['LossRatio'].max():.3f}\")\n",
        "        print(f\"Lowest risk (Loss Ratio): {risk_matrix['LossRatio'].min():.3f}\")\n",
        "    else:\n",
        "        print(\"Insufficient data for risk heatmap (need at least 50 policies per combination)\")\nelse:\n",
        "    print(\"Required columns for risk heatmap not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Outlier Detection {#outliers}\n",
        "\n",
        "Let's identify outliers in our key numerical variables using statistical methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_outliers(df, columns):\n",
        "    \"\"\"Detect outliers in key numerical columns using IQR method\"\"\"\n",
        "    \n",
        "    available_columns = [col for col in columns if col in df.columns]\n",
        "    if not available_columns:\n",
        "        print(\"No specified columns available for outlier detection\")\n",
        "        return {}\n",
        "    \n",
        "    n_cols = 2\n",
        "    n_rows = (len(available_columns) + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 6*n_rows))\n",
        "    if n_rows == 1:\n",
        "        axes = [axes] if n_cols == 1 else axes\n",
        "    else:\n",
        "        axes = axes.ravel()\n",
        "    \n",
        "    outlier_summary = {}\n",
        "    \n",
        "    for i, col in enumerate(available_columns):\n",
        "        if i < len(axes):\n",
        "            # Calculate IQR\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            \n",
        "            # Count outliers\n",
        "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
        "            outlier_summary[col] = {\n",
        "                'count': len(outliers),\n",
        "                'percentage': (len(outliers) / len(df)) * 100,\n",
        "                'lower_bound': lower_bound,\n",
        "                'upper_bound': upper_bound,\n",
        "                'Q1': Q1,\n",
        "                'Q3': Q3\n",
        "            }\n",
        "            \n",
        "            # Box plot\n",
        "            box_plot = axes[i].boxplot(df[col].dropna(), patch_artist=True)\n",
        "            box_plot['boxes'][0].set_facecolor('lightblue')\n",
        "            box_plot['boxes'][0].set_alpha(0.7)\n",
        "            \n",
        "            axes[i].set_title(f'{col}\\nOutliers: {len(outliers):,} ({(len(outliers)/len(df)*100):.1f}%)', \n",
        "                            fontsize=12, fontweight='bold')\n",
        "            axes[i].set_ylabel(col)\n",
        "            axes[i].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Add statistics as text\n",
        "            stats_text = f\"Q1: {Q1:.0f}\\nQ3: {Q3:.0f}\\nIQR: {IQR:.0f}\"\n",
        "            axes[i].text(0.02, 0.98, stats_text, transform=axes[i].transAxes, \n",
        "                        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "    \n",
        "    # Remove empty subplots\n",
        "    for i in range(len(available_columns), len(axes)):\n",
        "        fig.delaxes(axes[i])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return outlier_summary\n",
        "\n",
        "# Detect outliers in key columns\n",
        "key_columns = ['TotalPremium', 'TotalClaims', 'SumInsured', 'CustomValueEstimate']\n",
        "print(\"Outlier Detection Analysis:\")\n",
        "outlier_results = detect_outliers(df, key_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display outlier summary table\n",
        "if outlier_results:\n",
        "    outlier_df = pd.DataFrame(outlier_results).T\n",
        "    outlier_df = outlier_df.round(2)\n",
        "    outlier_df = outlier_df.sort_values('percentage', ascending=False)\n",
        "    \n",
        "    print(\"\\nOutlier Summary Table:\")\n",
        "    display(outlier_df)\n",
        "    \n",
        "    print(\"\\nKey Observations:\")\n",
        "    for col, stats in outlier_results.items():\n",
        "        print(f\"- {col}: {stats['count']:,} outliers ({stats['percentage']:.1f}% of data)\")\n",
        "        print(f\"  Valid range: ${stats['lower_bound']:.0f} - ${stats['upper_bound']:.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Key Findings and Insights {#findings}\n",
        "\n",
        "Based on our comprehensive EDA analysis, let's summarize the key findings and business insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate summary insights\n",
        "print(\"=\" * 60)\n",
        "print(\"EXECUTIVE SUMMARY - KEY FINDINGS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\n1. DATASET OVERVIEW:\")\n",
        "print(f\"   • Total records: {len(df):,}\")\n",
        "print(f\"   • Total features: {len(df.columns)}\")\n",
        "print(f\"   • Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
        "\n",
        "if 'TotalPremium' in df.columns and 'TotalClaims' in df.columns:\n",
        "    total_premium = df['TotalPremium'].sum()\n",
        "    total_claims = df['TotalClaims'].sum()\n",
        "    overall_loss_ratio = total_claims / total_premium\n",
        "    \n",
        "    print(\"\\n2. FINANCIAL PERFORMANCE:\")\n",
        "    print(f\"   • Total Premium Revenue: ${total_premium:,.0f}\")\n",
        "    print(f\"   • Total Claims Payout: ${total_claims:,.0f}\")\n",
        "    print(f\"   • Overall Loss Ratio: {overall_loss_ratio:.3f}\")\n",
        "    print(f\"   • Profitability Status: {'PROFITABLE' if overall_loss_ratio < 1.0 else 'LOSS-MAKING'}\")\n",
        "\n",
        "if outlier_results:\n",
        "    print(\"\\n3. DATA QUALITY INSIGHTS:\")\n",
        "    total_outliers = sum([stats['count'] for stats in outlier_results.values()])\n",
        "    print(f\"   • Total outliers detected: {total_outliers:,}\")\n",
        "    print(f\"   • Highest outlier percentage: {max([stats['percentage'] for stats in outlier_results.values()]):.1f}%\")\n",
        "\n",
        "missing_data = df.isnull().sum().sum()\n",
        "if missing_data > 0:\n",
        "    print(f\"   • Missing values: {missing_data:,} ({(missing_data/(len(df)*len(df.columns)))*100:.1f}% of total data)\")\nelse:\n",
        "    print(\"   • Data completeness: 100% (no missing values)\")\n",
        "\n",
        "print(\"\\n4. RECOMMENDATIONS:\")\n",
        "print(\"   • Monitor high-risk segments identified in loss ratio analysis\")\n",
        "print(\"   • Investigate outliers for potential data quality issues\")\n",
        "print(\"   • Consider premium adjustments for loss-making segments\")\n",
        "print(\"   • Implement regular monitoring of key performance indicators\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EDA ANALYSIS COMPLETE\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This comprehensive EDA has provided valuable insights into the insurance dataset, including:\n",
        "\n",
        "- **Data Quality Assessment**: Identified missing values, outliers, and data distribution patterns\n",
        "- **Financial Performance**: Analyzed overall profitability through loss ratios and premium/claims relationships\n",
        "- **Risk Segmentation**: Identified high and low-risk segments across different business dimensions\n",
        "- **Temporal Trends**: Understanding of business performance over time\n",
        "- **Correlation Analysis**: Key relationships between variables\n",
        "\n",
        "These insights can inform strategic decisions around pricing, risk assessment, and portfolio management.\n",
        "\n",
        "---\n",
        "\n",
        "*Next steps: Based on these findings, proceed with hypothesis testing and statistical modeling to validate insights and build predictive models.*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}